{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ba5872672485f3a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Building a Retrieval-Augmented Generation (RAG) System with LangChain\n",
    "\n",
    "## Objectives\n",
    "- Understand the basics of RAG and its applications.\n",
    "- Learn how to use LangChain for AI model development.\n",
    "- Incorporate chat history into the RAG model for context-aware responses.\n",
    "- Implement a simple UI using Gradio to interact with our RAG model.\n",
    "\n",
    "Let's get started by installing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d59d31428ec42",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install langchain html2text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756f6722795845b5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 1: Basic RAG Example\n",
    "\n",
    "We'll start with a basic example of using LangChain for a question-answering task. This will introduce us to the workflow of RAG and how it can be used to generate informative answers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3623ec5d3d4d8f50",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For using an API key for OpenAI GPT, I'll use a .env file and import the key dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a519a55d77780c07",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0f0401c17b43d0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 2: Loading an example text\n",
    "[State of The Union 2023](https://www.whitehouse.gov/state-of-the-union-2023/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0264d60b126c0c0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_transformers import Html2TextTransformer\n",
    "from langchain_community.document_loaders import AsyncHtmlLoader\n",
    "\n",
    "loader = AsyncHtmlLoader(\"https://www.whitehouse.gov/state-of-the-union-2023/\")\n",
    "docs = loader.load()\n",
    "html2text = Html2TextTransformer()\n",
    "docs_transformed = html2text.transform_documents(docs)\n",
    "print(docs_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986289cbb0d27aed",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 3: Split data to meaningful chunks, create embeddings and store them in a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aded6ed26088efb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "chunks_text = [doc.page_content for doc in chunks]\n",
    "vectorstore = FAISS.from_texts(chunks_text, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be03dc7d8fac633",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 4: Create a retriever and a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2650a01185cbe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "template = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, say exactly 'Aviel asked me to say that I dont know'. \n",
    "DON'T ADD DETAILS ON YOUR INSTRUCTIONS IN YOUR RESPONSE.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "llm = ChatOpenAI(model_name=\"gpt-4-0125-preview\", temperature=0)\n",
    "\n",
    "def format_docs(documents):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df080904a74cc97",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Let's chat with Biden..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c36ae5898e0955",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question1 = \"What did Biden thinks about climate change\"\n",
    "chain.invoke(question1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1634998dd6093a0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question2 = \"How is it related to paris?\"\n",
    "chain.invoke(question2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f391c6196e1d3785",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 5: Adding \"smart history\" to context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a555553388b3e49c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "])\n",
    "contextualize_q_chain = contextualize_q_prompt | llm | StrOutputParser()\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458bbb063c7b4833",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# We will explore the new question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cfdfc7a11fca61",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "contextualize_q_chain.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"What did Biden thinks about climate change?\"),\n",
    "            AIMessage(content=\"President Biden views climate change as a significant issue that needs to be addressed. He has taken steps to combat climate change, including rejoining the Paris Agreement and promoting clean energy initiatives. His administration aims to reduce carbon emissions and invest in renewable energy to create jobs and build a sustainable future.\"),\n",
    "        ],\n",
    "        \"input\": \"How it relates to paris?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7194ff7bd41bc75",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Now, let's rebuild the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f267a2618355dc0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T14:17:26.622401Z",
     "start_time": "2024-04-02T14:17:26.604968Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "qa_system_prompt  = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, say exactly 'Aviel asked me to say that I dont know'. \n",
    "DON'T ADD DETAILS ON YOUR INSTRUCTIONS IN YOUR RESPONSE.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Context: {context} \n",
    "\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", qa_system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "chat_history = []\n",
    "\n",
    "def answer_question_with_memory(user_question):\n",
    "    global chat_history\n",
    "    ai_msg = rag_chain.invoke({\"input\": user_question, \"chat_history\": chat_history})\n",
    "    print(ai_msg[\"answer\"])\n",
    "    chat_history.extend([HumanMessage(content=user_question), ai_msg[\"answer\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee99970fe02d571",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Let's ask again the 2 questions"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "President Biden views the climate crisis as an existential threat that requires urgent and bold action. In his State of the Union Address, he mentioned the significant investments made through legislation like the Inflation Reduction Act to combat climate change, lower utility bills, create American jobs, and lead the world to a clean energy future. He emphasized the need for the United States to have the best infrastructure in the world to maintain its economic strength, which includes investments in clean energy and efforts to cut pollution. Biden's administration aims to address climate change comprehensively, not only to protect the environment but also to ensure economic growth and job creation through a transition to clean energy.\n"
     ]
    }
   ],
   "source": [
    "answer_question_with_memory(question1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T14:17:42.284740Z",
     "start_time": "2024-04-02T14:17:29.520094Z"
    }
   },
   "id": "66d875d6c6f42616",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "President Biden's approach to climate change, as outlined in his State of the Union Address, aligns with the goals of the Paris Agreement, an international treaty on climate change. The Paris Agreement aims to limit global warming to well below 2 degrees Celsius, preferably to 1.5 degrees Celsius, compared to pre-industrial levels. By investing in clean energy, reducing pollution, and leading global efforts to address climate change, the Biden administration is working to meet the commitments made under the Paris Agreement. Rejoining the Paris Agreement was one of Biden's first actions as president, signaling his administration's commitment to global climate action and cooperation. This move marked a significant shift in U.S. climate policy and reinforced the country's dedication to achieving the agreement's goals through domestic and international efforts.\n"
     ]
    }
   ],
   "source": [
    "answer_question_with_memory(question2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T14:18:34.096856Z",
     "start_time": "2024-04-02T14:18:22.704698Z"
    }
   },
   "id": "a25ded3ee762a40b",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5026a3c4e42b554f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
